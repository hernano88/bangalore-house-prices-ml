# Proyecto PredicciÃ³n de precios inmobiliarios (Bangalore)

Modelo de Machine Learning en Python (Jupyter) para estimar precios de viviendas en Bangalore a partir de variables como superficie, ambientes (BHK), baÃ±os y ubicaciÃ³n. Incluye limpieza de datos, tratamiento de outliers, codificaciÃ³n de ubicaciones y comparaciÃ³n de modelos.

---

## ğŸ¯ Objetivo

- Preparar y limpiar el dataset Bengaluru_House_Data.csv.

- Normalizar superficies con rangos (ej. â€œ2100â€“2850â€) y crear BHK y precio por mÂ²/pie.

- Reducir outliers por ubicaciÃ³n y por inconsistencias entre categorÃ­as de BHK.

- Entrenar y evaluar modelos (Linear Regression, Lasso, Decision Tree) con validaciÃ³n cruzada.

- Exportar el modelo entrenado (.pickle) y el esquema de columnas (columns.json) para predicciÃ³n.

---

## ğŸ› ï¸ Desarrollo

1) Carga y depuraciÃ³n

- Dropeo de columnas de baja incidencia: availability, society, balcony, area_type.

- EliminaciÃ³n de nulos y normalizaciÃ³n de strings (trim en location).

- ExtracciÃ³n de BHK desde size (ej. â€œ3 BHKâ€ â†’ bhk = 3).

- ConversiÃ³n de total_sqft:

Si viene en rango (ej. 2100-2850) se toma el promedio.

Si no es convertible a nÃºmero, se marca como None y se filtra.

- CreaciÃ³n de price_per_sqft = price * 100000 / total_sqft.

2) Ubicaciones y rareza

- Conteo por location, las ubicaciones con â‰¤10 registros se agrupan como other.

3) Reglas de outliers

- Regla de densidad mÃ­nima: eliminar propiedades con total_sqft / bhk < 300.

- Outliers por ubicaciÃ³n (funciÃ³n remove_pps_outliers):

Por cada location, se queda con precios por mÂ² dentro de [Î¼ âˆ’ Ïƒ, Î¼ + Ïƒ].

- Outliers por BHK (funciÃ³n remove_bhk_outliers):

En una misma ubicaciÃ³n, si la categorÃ­a BHK n tiene price_per_sqft < media de BHK (nâˆ’1) (con suficiente soporte), se excluye.

Previo proceso

![Previo proceso](fotos/pre.PNG)

Post proceso

![Previo proceso](fotos/post.PNG)

4) Modelado y evaluaciÃ³n

- Split 80/20 con train_test_split.

- Modelos:

Linear Regression

Lasso Regression

Decision Tree Regressor

- ValidaciÃ³n cruzada con ShuffleSplit y bÃºsqueda de hiperparÃ¡metros con GridSearchCV.

- MÃ©trica principal: RÂ².

5) ExportaciÃ³n y predicciÃ³n

- Se guarda el modelo final con pickle.

- Se exporta el orden de columnas para inferencia con columns.json.

- FunciÃ³n de predicciÃ³n lista para usar: predict_price(location, total_sqft, bath, bhk).

---

## ğŸ“¸ Ejemplos (cÃ³digo del notebook)

SelecciÃ³n de modelo con GridSearchCV (Linear Regression, Lasso, Decision Tree), destacando Linear Regression como el mÃ¡s performante 

![Previo proceso](fotos/proceso.PNG)

---

## ğŸ“Š Resultados

- Dataset depurado con reducciÃ³n de ruido y outliers (mejora la estabilidad del modelo).

- RÂ² (test) y mean CV score (completar con tus nÃºmeros al ejecutar el notebook).

- predict_price() operativo para estimar precios por ubicaciÃ³n, superficie, baÃ±os y BHK.

- Artefactos listos para despliegue: banglore_home_prices_model.pickle + columns.json.

---

## ğŸ”§ TecnologÃ­as utilizadas

- Python (Pandas, NumPy)

- Matplotlib (visualizaciÃ³n)

- Scikit-learn (Linear Regression, Lasso, Decision Tree, ShuffleSplit, GridSearchCV)

- Pickle / JSON (artefactos para inferencia)

- Jupyter Notebook
